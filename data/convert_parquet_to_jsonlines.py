# -*- coding: utf-8 -*-
"""convert_jsonlines.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pUHroT9hbenxdf3mYmvNOZl9sgTfSQl_
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade --user --quiet jsonlines

"""### Restart runtime (Colab only)

To use the newly installed packages, you must restart the runtime on Google Colab.

"""

import sys

if "google.colab" in sys.modules:
    import IPython

    app = IPython.Application.instance()
    app.kernel.do_shutdown(True)

"""<div class="alert alert-block alert-warning">
<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>
</div>

## Step1: Import Libraries
"""

import jsonlines
import pandas as pd

# mount google drive
from google.colab import drive
drive.mount('/content/drive')

def filter_dataset(df: pd.DataFrame) -> pd.DataFrame:
  # drop na
  df = df.dropna()
  # remove any rows that have "<figure>" or "<formula>" on the `sentence` column
  df = df[~df['sentence'].str.contains('<figure>|<formula>')]

  # return shuffled version
  return df.sample(frac=1).reset_index(drop=True)

def construct_dataset(df: pd.DataFrame, n: int=10000) -> pd.DataFrame:
  # get 5000 positive samples (True on the `citing` column)
  positive_samples = df[df['citing'] == True].sample(n=n // 2, random_state=42)
  # get 5000 negative samples
  negative_samples = df[df['citing'] == False].sample(n=n // 2, random_state=42)

  # combine results and shuffle
  combined_df = pd.concat([positive_samples, negative_samples]).sample(frac=1).reset_index(drop=True)

  return combined_df

TRAIN_PATH = '/content/drive/MyDrive/citing_sentence_dataset/citing_train.parquet'

df_train = pd.read_parquet(TRAIN_PATH)

df_train = filter_dataset(df_train)
df_train = construct_dataset(df_train)

df_train.head(20)

VAL_PATH = '/content/drive/MyDrive/citing_sentence_dataset/citing_val.parquet'

df_val = pd.read_parquet(VAL_PATH)

df_val = filter_dataset(df_val)
df_val = construct_dataset(df_val, 5000)

def to_jsonlines(df: pd.DataFrame, path: str) -> None:
  with jsonlines.open(path, mode='w') as writer:
    instances = []
    for row in df.itertuples():
      instance = {
          "contents": [
              {
                  "role": "user",
                  "parts": [{"text": row.sentence}]
              },
              {
                  "role": "model",
                  "parts": [{"text": "yes" if row.citing else "no"}]
              }
          ]
      }

      instances.append(instance)

    writer.write_all(instances)

to_jsonlines(df_train, '/content/citing_train.jsonl')

to_jsonlines(df_val, '/content/citing_val.jsonl')